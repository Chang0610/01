{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d299a6-0876-4fc5-ba27-0405895c0f4e",
   "metadata": {},
   "source": [
    "# 1. Using Ray for Distributed Computing and Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5fce01-9ebc-4c23-b8bd-b0c9abb84c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ray\n",
    "\n",
    "import ray\n",
    "import pandas as pd\n",
    "\n",
    "# Shut down any previously running Ray instance\n",
    "ray.shutdown()\n",
    "\n",
    "# Initialize Ray\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "# Define a remote function to parallelize data loading\n",
    "@ray.remote\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# List of file paths for climate data\n",
    "file_paths = ['total_precipitation/precipitation_data.csv', 'sunshine_duration/sunshine_data.csv']\n",
    "\n",
    "# Load data in parallel using Ray\n",
    "data_futures = [load_data.remote(file_path) for file_path in file_paths]\n",
    "climate_data = ray.get(data_futures)\n",
    "\n",
    "# Process loaded data\n",
    "total_precipitation, sunshine_data = climate_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f2a27-8157-4323-acf7-68e02bf8e846",
   "metadata": {},
   "source": [
    "# 2. Training Models in a Distributed Fashion with Ray Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7289bfad-757d-478b-b424-c17895159d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.sklearn import SklearnTrainer\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Define model configurations\n",
    "models = {\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'GradientBoosting': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Train model in parallel using Ray Train\n",
    "def train_model(config):\n",
    "    model = models[config['model_type']]\n",
    "    model.fit(X_train, y_train)  # Replace with actual training data\n",
    "    return model.score(X_test, y_test)  # Return model performance\n",
    "\n",
    "train_config = {\n",
    "    \"model_type\": \"RandomForest\"\n",
    "}\n",
    "\n",
    "trainer = SklearnTrainer(train_func=train_model, scaling_config=ScalingConfig(num_workers=4))\n",
    "result = trainer.fit(train_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6a08e2-760c-4180-823c-1b28860127fe",
   "metadata": {},
   "source": [
    "# 3. Optimizing DAG-Based Workflows with Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e93d24-8f8b-4d60-b00e-02ba4106ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.dag import InputNode\n",
    "\n",
    "# Define a DAG for the preprocessing pipeline\n",
    "@ray.remote\n",
    "def preprocess_data(data):\n",
    "    # Your data preprocessing logic here\n",
    "    return data\n",
    "\n",
    "@ray.remote\n",
    "def train_model_dag(data):\n",
    "    # Train the model using the preprocessed data\n",
    "    return model.fit(data)\n",
    "\n",
    "# Create a DAG input node\n",
    "data_input = InputNode()\n",
    "\n",
    "# Create the preprocessing step in the DAG\n",
    "preprocessed_data = preprocess_data.bind(data_input)\n",
    "\n",
    "# Create the training step in the DAG\n",
    "model_output = train_model_dag.bind(preprocessed_data)\n",
    "\n",
    "# Run the DAG\n",
    "model_output.execute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b23c5-4720-4efa-8f8f-1595b9c6f296",
   "metadata": {},
   "source": [
    "# 4. Hyperparameter Tuning with Ray Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fdfee3-89bd-442c-b982-177230d5bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define hyperparameter search space\n",
    "param_space = {\n",
    "    \"alpha\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"fit_intercept\": tune.choice([True, False])\n",
    "}\n",
    "\n",
    "def train_model_with_tune(config):\n",
    "    model = Ridge(alpha=config['alpha'], fit_intercept=config['fit_intercept'])\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    tune.report(score=score)\n",
    "\n",
    "# Run hyperparameter tuning\n",
    "tune.run(\n",
    "    train_model_with_tune,\n",
    "    config=param_space,\n",
    "    num_samples=10,\n",
    "    scheduler=ASHAScheduler()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71db892-2d0e-4743-9d46-8b26007f4dcf",
   "metadata": {},
   "source": [
    "# 5. Deploying Models with Ray Serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69471aad-f106-4e4a-8ea2-ab56fe1ab4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import serve\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize Ray Serve\n",
    "serve.start()\n",
    "\n",
    "# Define a deployment class for the model\n",
    "@serve.deployment\n",
    "class ModelDeployment:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestRegressor().fit(X_train, y_train)\n",
    "    \n",
    "    def predict(self, data):\n",
    "        return self.model.predict([data])\n",
    "\n",
    "# Deploy the model\n",
    "ModelDeployment.deploy()\n",
    "\n",
    "# Send a test request to the model\n",
    "handle = ModelDeployment.get_handle()\n",
    "result = ray.get(handle.predict.remote([0.5, 0.3, 0.2]))\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4eb63d-3bb0-4f39-ad4b-b256d4fe2602",
   "metadata": {},
   "source": [
    "# 6. Advanced Model Deployment with Accelerated DAG (ADAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c2aa0-8063-401a-a752-214f51074d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced usage of DAGs for complex ML pipelines\n",
    "from ray.dag import DAGNode\n",
    "\n",
    "@ray.remote\n",
    "def data_preprocessing_step(data):\n",
    "    # Your preprocessing logic\n",
    "    return processed_data\n",
    "\n",
    "@ray.remote\n",
    "def model_training_step(processed_data):\n",
    "    # Your training logic\n",
    "    return trained_model\n",
    "\n",
    "# Create a DAG node\n",
    "data_input = InputNode()\n",
    "\n",
    "# Create DAG for preprocessing and training steps\n",
    "preprocessed_data = data_preprocessing_step.bind(data_input)\n",
    "trained_model = model_training_step.bind(preprocessed_data)\n",
    "\n",
    "# Execute the DAG\n",
    "trained_model.execute()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
